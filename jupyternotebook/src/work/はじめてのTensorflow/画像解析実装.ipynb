{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Pillowの基本的な使い方に慣れてきたところで、一般的な画像に対する分類問題を解いてみましょう。 画像データを学習に使用できるよう、入力層へ渡せる形式へ変換した後、4.2節と同じくCNNを実装し画像を分類してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "#層の作成、学習に必要なライブラリの読み込み\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "## 画像データの処理\n",
    "\n",
    "# 学習用の画像ファイルを格納しているディレクトリ\n",
    "train_dirs = ['pos','neg']\n",
    "\n",
    "# 学習データを格納する配列の準備\n",
    "trainX = [] #画像ピクセル値\n",
    "trainY = [] #正解データ\n",
    "\n",
    "for i,d in enumerate(train_dirs):\n",
    "    #ファイル名の取得\n",
    "    files = os.listdir('./data/pict/' + d)\n",
    "    for f in files:\n",
    "        #画像読み込み\n",
    "        image = Image.open('./data/pict/' + d + '/' + f, 'r')\n",
    "        #グレースケールへ変換\n",
    "        gray_image = image.convert('L')\n",
    "        # 画像ファイルをピクセル値へ変換\n",
    "        gray_image_px = np.array(gray_image)\n",
    "        #gray_image_pxをフラット（一次元配列）に変換\n",
    "        gray_image_flatten = gray_image_px.flatten().astype(np.float32)/255.0\n",
    "        trainX.append(gray_image_flatten)\n",
    "        \n",
    "        # 正解データをone_hot形式へ変換\n",
    "        tmp = np.zeros(2)\n",
    "        tmp[i] = 1\n",
    "        trainY.append(tmp)\n",
    "\n",
    "# numpy配列に変換\n",
    "trainX = np.asarray(trainX)\n",
    "trainY = np.asarray(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26666668 0.42745098 0.45882353 ... 0.27450982 0.2784314  0.29803923]\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "#1枚目の画像ピクセルデータを表示\n",
    "print(trainX[0])\n",
    "print(trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 1枚目の画像ピクセル値と正解データの長さを表示\n",
    "print(len(trainX[0]))\n",
    "print(len(trainY[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1枚目の画像ピクセルデータは、サイズが1024（32×32×1）の1次元配列に格納されており、正解データはサイズが2（posとnegの2値）の1次元配列に格納されていることが分かります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.26666668],\n",
       "        [0.42745098],\n",
       "        [0.45882353],\n",
       "        ...,\n",
       "        [0.4745098 ],\n",
       "        [0.5137255 ],\n",
       "        [0.5294118 ]],\n",
       "\n",
       "       [[0.35686275],\n",
       "        [0.75686276],\n",
       "        [0.827451  ],\n",
       "        ...,\n",
       "        [0.4745098 ],\n",
       "        [0.4862745 ],\n",
       "        [0.47058824]],\n",
       "\n",
       "       [[0.34901962],\n",
       "        [0.6156863 ],\n",
       "        [0.8039216 ],\n",
       "        ...,\n",
       "        [0.4509804 ],\n",
       "        [0.45882353],\n",
       "        [0.4627451 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.03137255],\n",
       "        [0.02745098],\n",
       "        [0.00392157],\n",
       "        ...,\n",
       "        [0.29803923],\n",
       "        [0.27058825],\n",
       "        [0.30980393]],\n",
       "\n",
       "       [[0.01568628],\n",
       "        [0.04313726],\n",
       "        [0.04705882],\n",
       "        ...,\n",
       "        [0.3372549 ],\n",
       "        [0.32941177],\n",
       "        [0.32156864]],\n",
       "\n",
       "       [[0.02352941],\n",
       "        [0.04313726],\n",
       "        [0.07450981],\n",
       "        ...,\n",
       "        [0.27450982],\n",
       "        [0.2784314 ],\n",
       "        [0.29803923]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#画像ピクセルデータを1次元から2次元へ変換\n",
    "#CNNを使って学習するために、学習（入力）データは2次元でなければなりません。\n",
    "trainX = trainX.reshape([-1,32,32,1])\n",
    "#1枚目の画像ピクセル値を表示\n",
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "#1枚目のサイズ\n",
    "print(len(trainX[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、入力層が32×32ノード、中間層は畳み込み層、プーリング層が2層ずつ、全結合層が1層、出力層が2ノード（posとnegの2種類）から成るCNNを構築し、\n",
    "モデルの分類精度を確かめます。畳み込み層で使用するフィルタのサイズは5とし、プーリング層の領域のサイズは2とします。また、全結合層のノード数を128とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.72295\u001b[0m\u001b[0m | time: 0.400s\n",
      "| SGD | epoch: 020 | loss: 0.72295 - acc: 0.5418 -- iter: 384/387\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.72329\u001b[0m\u001b[0m | time: 1.441s\n",
      "| SGD | epoch: 020 | loss: 0.72329 - acc: 0.5220 | val_loss: 0.65305 - val_acc: 0.6495 -- iter: 387/387\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# ニューラルネットワークの作成\n",
    "\n",
    "## 初期化\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## 入力層の作成\n",
    "# input_data関数を使って入力層を作成します。\n",
    "# 1番目の引数shapeには、入力する学習データの形状として、バッチサイズとノード数を設定します。\n",
    "# ここでは、None（ここでは指定しない）と、32×32（画像1枚あたりのピクセル数）、1（グレースケール画像）とします。\n",
    "net = input_data(shape=[None, 32, 32, 1])\n",
    "\n",
    "## 中間層の作成\n",
    "# 畳み込み層の作成\n",
    "#●1番目の引数：作成する層の1つ前の層（結合の対象となる層）を設定します。ここでは、netにあたります。\n",
    "#●2番目の引数：畳み込みフィルタ数（出力次元数）を設定します。ここでは、1番目の畳み込み層では32とします。\n",
    "#●3番目の引数：フィルタのサイズを設定します。ここでは、5×5とします。\n",
    "#●4番目の引数：使用する活性化関数を設定します。ここでは、relu（ReLU関数）を使用します。\n",
    "#●また、引数として明示的に設定していませんが、ゼロパディングを行ってサイズを保持しています。同様に、フィルタは1ずつスライドします。\n",
    "net = conv_2d(net, 32, 5, activation='relu')\n",
    "\n",
    "# プーリング層の作成\n",
    "# ●1番目の引数：作成する層の1つ前の層を設定します。ここでは、netにあたります。\n",
    "# ●2番目の引数：最大プーリングを行う領域を設定します。ここでは、2×2とします。\n",
    "net = max_pool_2d(net, 2)\n",
    "\n",
    "# 畳み込み層の作成\n",
    "# ●1番目の引数：作成する層の1つ前の層（結合の対象となる層）を設定します。ここでは、netにあたります。\n",
    "# ●2番目の引数：畳み込みフィルタ数（出力次元数）を設定します。ここでは、1つ目の畳み込み層では64とします。\n",
    "#●3番目の引数：フィルタのサイズを設定します。ここでは、5×5とします。\n",
    "#●4番目の引数：使用する活性化関数を設定します。ここでは、relu（ReLU関数）を使用します。\n",
    "#●また、引数として明示的に設定していませんが、ゼロパディングを行ってサイズを保持しています。同様に、フィルタは1ずつスライドします。\n",
    "net = conv_2d(net, 64, 5, activation='relu')\n",
    "\n",
    "# プーリング層の作成\n",
    "# ●1番目の引数：作成する層の1つ前の層を設定します。ここでは、netにあたります。\n",
    "# ●2番目の引数：最大プーリングを行う領域を設定します。ここでは、2×2とします。\n",
    "# 入力層における32×32×1サイズのデータは、1層目の畳み込み層で32×32×32サイズとなり、1層目のプーリング層で16×16×32サイズとなり、2層目の畳み込み層で16×16×64サイズとなり、2層目のプーリング層で8×8×64サイズとなります。\n",
    "nat = max_pool_2d(net, 2)\n",
    "\n",
    "# 全結合層の作成\n",
    "# ●1番目の引数：作成する層の1つ前の層（結合の対象となる層）を設定します。ここでは、netにあたります。\n",
    "# ●2番目の引数：作成する層のノード数を設定します。ここでは、128とします。\n",
    "# ●3番目の引数：使用する活性化関数を設定します。ここでは、relu（ReLU関数）とします。\n",
    "net = fully_connected(net, 128, activation='relu')\n",
    "\n",
    "#dropout関数を使って、作成した層に対しドロップアウトを行います。\n",
    "#●1番目の引数：ドロップアウトの対象とする層を設定します。ここでは、netにあたります。\n",
    "#●2番目の引数：対象となる層の全ノードのうち何割を残しておくか、その比率を設定します。ここでは、0.5とします。\n",
    "net = dropout(net, 0.5)\n",
    "\n",
    "## 出力層の作成\n",
    "# ●1番目の引数：作成する層の1つ前の層（結合の対象となる層）を設定します。ここでは、netにあたります。\n",
    "# ●2番目の引数：作成する層のノード数を設定します。ここでは、2とします（posとnegの2種類あるため）。\n",
    "# ●3番目の引数：作成する層で使用する活性化関数を設定します。ここでは、softmax（ソフトマックス関数）を使用します。\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "\n",
    "# regression関数を使って、学習の条件を設定します。\n",
    "# ●1番目の引数：学習の対象となる層を設定します。ここでは、これまで作成してきた層であるnetにあたります。\n",
    "# ●2番目の引数：最適化の手法を設定します。ここでは、sgd（確率的勾配降下法）を使用します。\n",
    "# ●3番目の引数：学習係数の減衰係数を設定します。ここでは、0.5とします。\n",
    "# ●4番目の引数：誤差関数を設定します。ここでは、categorical_crossentropy（交差エントロピー）を使用します。\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.5, loss='categorical_crossentropy')\n",
    "\n",
    "## モデルの作成（学習） ##\n",
    "#学習の実行\n",
    "# DNN関数を使って、作成したニューラルネットワークと学習条件をセットします。\n",
    "#●1番目の引数：セットする対象のニューラルネットワークを設定します。ここでは、netにあたります。\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "# fit関数を使って学習を実行し、モデルを作成します。\n",
    "# ●1番目の引数：学習データを設定します。ここでは、学習用の画像ピクセルデータを格納した配列trainXです。\n",
    "# ●2番目の引数：正解データを設定します。ここでは、学習用の画像正解データを格納した配列trainYです。\n",
    "# ●3番目の引数：エポック数（≒学習回数）を設定します。ここでは、20とします。\n",
    "# ●4番目の引数：バッチサイズを設定します。ここでは32とします。\n",
    "# ●5番目の引数：モデルの精度を検証するためのテストデータセットを設定します。ここでは、学習用データセットのうちの2割（0.2）とします。\n",
    "# ●6番目の引数：学習のステップごとに精度を表示するかどうかを設定します。ここでは、True（表示する）とします。\n",
    "model.fit(trainX, trainY, n_epoch=20, batch_size=32, validation_set=0.2, show_metric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "本章の前半では、畳み込みニューラルネットワーク（CNN）の仕組みと学習方法を説明しました。\n",
    "CNNでは第3章で扱った全結合型のニューラルネットワークと異なり、中間層に畳み込み層とプーリング層を導入します。\n",
    "畳み込み層はフィルタを介してデータの特徴量を抽出し、プーリング層は特徴量を圧縮します。これによって位置のズレを吸収し、見え方の違いによるズレを小さくする役割を果たします。\n",
    "本章の中盤では、TFLearnライブラリを使ってCNNを実装し、手書き文字画像MNISTデータセットの分類問題に挑戦しました。\n",
    "学習に使用するデータの整形やCNNの実装、学習の実行を通して、前半の内容に関する理解が深まったことでしょう。\n",
    "本章の後半では、Pythonの画像処理ライブラリPillowを使って、JPEG形式やPNG形式などの画像ファイルを、ピクセル値と正解データへ変換する方法を説明しました。\n",
    "また、学習に使用する画像枚数が少ない場合の対処法として、画像を加工して枚数を増やす方法についてもとりあげました。\n",
    "これらの処理は、画像処理ソフトOpenCV(注1)を使って行うことも可能です。そして、CNNを実装し画像を分類する問題に挑戦しました。\n",
    "これで皆さんは、画像データを使って学習することができるようになりました。\n",
    "CNNを使えば、第3章の全結合型ニューラルネットワークを用いたときよりも、高い精度で分類することができました。\n",
    "今後も、画像の分類問題にはまずCNNを用いてみましょう。\n",
    "次章では、再帰型ニューラルネットワーク（RecurrentNeuralNetwork：RNN）の仕組みを理解し、実装してみましょう。\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.1.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
